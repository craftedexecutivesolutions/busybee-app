INTRODUCTION TO MACHINE LEARNING
Computer Science 4430 - Fall 2024
University Lecture Hall C
November 15, 2024, 10:00 AM - 11:30 AM

PROFESSOR: Dr. Amanda Chen
STUDENTS: Approximately 45 students present

DR. CHEN: Good morning everyone. I hope you all had a chance to review the reading assignment on supervised learning algorithms. Today we're diving into one of the most fundamental concepts in machine learning - the difference between supervised, unsupervised, and reinforcement learning.

But before we get into the technical details, let me ask you this: How many of you used a recommendation system today? Maybe Netflix suggested a show, or Amazon recommended a product, or Spotify created a playlist for you?

[Several students raise hands]

That's what I thought. You're all already consumers of machine learning, even if you don't realize it. The algorithms we'll discuss today power most of these systems.

Let's start with the big picture. Machine learning is essentially about finding patterns in data and using those patterns to make predictions or decisions. But the way we approach this problem depends on what kind of data we have and what we're trying to achieve.

The three main paradigms are supervised learning, unsupervised learning, and reinforcement learning. Think of them like three different ways of teaching a child.

Supervised learning is like teaching with flashcards. You show the child a picture of a cat and say "cat," show them a picture of a dog and say "dog." You're providing both the input - the picture - and the correct answer - the label. The child learns to associate visual features with the correct labels.

In machine learning terms, supervised learning means we have a dataset with input examples and the correct outputs. We train our algorithm on this labeled data so it can make predictions on new, unlabeled examples.

The two main types of supervised learning are classification and regression. Who can tell me the difference?

STUDENT 1: Classification is when you're predicting categories, like spam or not spam. Regression is when you're predicting a number, like a house price.

DR. CHEN: Exactly right. Classification gives you discrete categories - spam/not spam, cat/dog/bird, fraud/legitimate transaction. Regression gives you continuous values - house prices, stock prices, temperature predictions.

Let me give you some concrete examples. Email spam detection is classification - each email is either spam or not spam. Credit scoring is also classification - approve or deny the loan. Image recognition is classification - is this a cat, dog, or bird?

For regression examples, think about predicting house prices based on square footage, location, and amenities. Or forecasting sales revenue based on advertising spend and market conditions. These all produce numerical outputs along a continuous scale.

Now, the key insight with supervised learning is that we need labeled training data. Someone had to go through thousands of emails and mark them as spam or legitimate. Someone had to tag photos as cats or dogs. This labeling process is often the most expensive and time-consuming part of a machine learning project.

Let's talk about some common supervised learning algorithms. Probably the most intuitive is k-nearest neighbors, or KNN. 

Imagine you're trying to classify a new data point. KNN looks at the k closest points in your training data and takes a majority vote. If k equals 5, and 3 of the 5 nearest neighbors are labeled "cat" while 2 are labeled "dog," then KNN predicts "cat."

The beauty of KNN is its simplicity - it makes very few assumptions about your data. The downside is that it can be computationally expensive for large datasets since you have to calculate distances to all training points.

Another fundamental algorithm is linear regression. This tries to fit a straight line through your data points to minimize prediction errors. For multiple features, it fits a hyperplane instead of just a line.

Linear regression works well when relationships in your data are roughly linear, but struggles with complex, non-linear patterns. That's where more sophisticated algorithms like decision trees and neural networks come in.

Decision trees are particularly interesting because they mirror human decision-making. The algorithm builds a tree of yes/no questions that best separate your classes. For example, to classify animals, it might ask: "Does it have fur?" If yes, "Does it bark?" This creates a hierarchy of decisions.

The advantage of decision trees is interpretability - you can literally trace the logic. The disadvantage is they tend to overfit, meaning they memorize training data rather than learning general patterns.

Now let's shift to unsupervised learning. Going back to our child analogy, this is like giving a child a box of mixed toys and asking them to organize them, without telling them how to categorize.

In unsupervised learning, we only have input data - no labels, no correct answers. The algorithm has to find hidden structure or patterns on its own.

The most common type is clustering - grouping similar data points together. K-means is a popular clustering algorithm. You specify k, the number of clusters you want, and the algorithm groups your data into k clusters by minimizing the distance within each cluster.

For example, if you have customer data - age, income, spending habits - k-means might discover natural customer segments like "young budget shoppers," "middle-aged luxury buyers," and "senior savers."

Another important unsupervised technique is dimensionality reduction. This is useful when you have datasets with hundreds or thousands of features. Principal Component Analysis, or PCA, finds the most important dimensions that capture the most variation in your data.

Imagine you're analyzing student performance and you have test scores for 50 different subjects. PCA might discover that most of the variation can be explained by just 3 underlying factors - maybe "mathematical ability," "verbal skills," and "creative thinking."

Association rule learning is another unsupervised technique. This finds relationships between different items. The classic example is market basket analysis - "people who buy bread and milk often also buy eggs." Amazon's "customers who bought this also bought" feature uses similar logic.

Finally, we have reinforcement learning. This is like teaching a child to ride a bike. You don't give them a manual with every possible scenario. Instead, they learn through trial and error, getting feedback on their actions.

In reinforcement learning, an agent takes actions in an environment and receives rewards or penalties. The goal is to learn a policy - a strategy for choosing actions that maximizes long-term reward.

This is how AlphaGo learned to play Go at a superhuman level. It played millions of games against itself, receiving positive rewards for winning moves and negative rewards for losing moves. Over time, it developed incredibly sophisticated strategies.

Reinforcement learning is particularly powerful for sequential decision-making problems. Think about autonomous vehicles - each driving decision affects future options and outcomes. Or game playing, where current moves set up future opportunities.

The challenge with reinforcement learning is that it often requires a lot of trial and error. The agent might have to take many random actions before it starts finding successful strategies. This is why simulation environments are so important - you can't have a real car crashing thousands of times while it learns to drive.

Now, let's talk about some practical considerations. How do you choose which approach to use?

If you have labeled data and want to predict specific outcomes, supervised learning is usually the way to go. The key question is whether you're predicting categories (classification) or numbers (regression).

If you have data but no specific target variable, and you want to discover hidden patterns, try unsupervised learning. Clustering can reveal customer segments, dimensionality reduction can simplify complex datasets, and association rules can find unexpected relationships.

If you have a sequential decision-making problem where you can define rewards and penalties, reinforcement learning might be appropriate. But be prepared for longer training times and the need for simulation environments.

One crucial concept across all these approaches is the bias-variance tradeoff. Bias refers to systematic errors from overly simplistic assumptions. High bias means your model consistently misses relevant patterns.

Variance refers to sensitivity to small changes in training data. High variance means your model changes dramatically when you add or remove a few training examples.

The goal is to find the sweet spot - a model complex enough to capture important patterns (low bias) but stable enough to generalize to new data (low variance).

Simple models like linear regression tend to have high bias but low variance. Complex models like deep neural networks can have low bias but high variance if not properly regularized.

This brings us to overfitting - probably the most important concept for practical machine learning. Overfitting happens when your model memorizes the training data rather than learning generalizable patterns.

Imagine studying for a test by memorizing every practice question exactly. You might ace those specific questions but fail completely on new questions that test the same concepts differently.

The solution is to always evaluate your model on data it hasn't seen during training. We typically split our data into training, validation, and test sets. Train on the training set, tune hyperparameters using the validation set, and get your final performance estimate from the test set.

Cross-validation is another important technique. Instead of a single train-test split, you divide your data into k folds and train k different models, each using a different fold as the test set. This gives you a more robust estimate of model performance.

Let me give you some practical advice for your projects. Start simple - try linear models or basic decision trees before jumping to complex algorithms. Often, simple approaches work surprisingly well and are much easier to debug and interpret.

Feature engineering is usually more important than algorithm choice. Spending time creating good input features - combining, transforming, or selecting the most relevant variables - often improves results more than switching algorithms.

Always establish a baseline. If you're predicting customer churn and 90% of customers don't churn, then predicting "no churn" for everyone gives you 90% accuracy. Your fancy machine learning model needs to beat this simple baseline to be useful.

Pay attention to your evaluation metrics. Accuracy is intuitive but can be misleading with imbalanced classes. For classification, also consider precision, recall, and F1-score. For regression, look at mean squared error or mean absolute error.

And remember - machine learning is not magic. It can only find patterns that exist in your data. If your training data is biased or unrepresentative, your model will be too. Garbage in, garbage out.

Let's look at some real-world applications to cement these concepts.

Netflix uses supervised learning to predict ratings - they have training data of user ratings on movies and want to predict ratings for unwatched movies. They also use unsupervised learning to find groups of similar users or similar movies for their recommendation clusters.

Google's search algorithm uses supervised learning to predict which pages are most relevant to your query, trained on billions of click-through patterns. They also use unsupervised learning to understand the semantic relationships between words and topics.

Financial institutions use supervised learning for fraud detection, trained on historical examples of fraudulent and legitimate transactions. They use unsupervised learning to detect unusual patterns that might indicate new types of fraud.

Autonomous vehicles use all three paradigms. Supervised learning for object recognition - is that a pedestrian or a traffic sign? Unsupervised learning to understand typical traffic patterns. And reinforcement learning to make driving decisions in complex, dynamic environments.

As we wrap up, I want you to remember that machine learning is fundamentally about automation. We're automating the process of finding patterns in data and making predictions. The key is choosing the right approach based on your data and objectives.

For next class, I want you to read Chapter 3 on model evaluation and think about a machine learning problem you'd like to work on for your final project. Consider what type of learning paradigm would be most appropriate and what challenges you might face with data collection and evaluation.

We'll start next lecture by discussing your project ideas and diving deeper into specific algorithms. Are there any questions about today's material?

STUDENT 2: How do you know if your model is actually learning or just memorizing?

DR. CHEN: Great question. That's exactly what the train-validation-test split addresses. If your model performs well on training data but poorly on validation data, it's memorizing rather than learning. We'll dive deeper into this next class.

STUDENT 3: Can you combine different types of learning in one project?

DR. CHEN: Absolutely. Many real-world systems use hybrid approaches. You might use unsupervised learning for feature engineering, then supervised learning for prediction. Or combine supervised learning for initial training with reinforcement learning for online adaptation. Modern AI systems rarely stick to just one paradigm.

Any other questions? No? Alright, see you next Tuesday. Don't forget the reading assignment!

---

Lecture concluded at 11:28 AM
Next lecture: November 19, 2024 - Model Evaluation and Specific Algorithms
Reading assignment: Chapter 3 - Model Evaluation Methods